{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch-tfrecords.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch TPU + TF Records"
      ],
      "metadata": {
        "id": "s3RG7UEInkSG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vrp4qpPznSy3"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
        "LOCATION = 'us-central1' \n",
        "!gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()"
      ],
      "metadata": {
        "id": "S2_NP5Psnf9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in sys.modules:\n",
        "  USER_FLAG = ''\n",
        "else:\n",
        "  USER_FLAG = '--user'"
      ],
      "metadata": {
        "id": "0iq_iXL3nhWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pip install"
      ],
      "metadata": {
        "id": "fmNvzxexnlaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cloud-tpu-client==0.10 torch==1.11.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl\n",
        "\n",
        "! pip install tensorflow\n",
        "\n",
        "! pip -q install google-cloud-storage==1.44.0\n",
        "\n",
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "DYkssegznmrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import packages"
      ],
      "metadata": {
        "id": "clTmTT5Mns30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, IterableDataset, DataLoader\n",
        "\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.utils.utils as xu\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from itertools import cycle, islice, chain, count\n",
        "import random \n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from google.cloud import storage\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "fJ-LcQKHnrJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF vs Torch Tensors\n",
        "\n",
        "* N - batch size\n",
        "* H - height of image\n",
        "* W - width of image\n",
        "* C - numberof channels (usually 3 for RGB)\n",
        "\n",
        "Tensorflow \n",
        "* `shape=(N, H, W, C)`\n",
        "\n",
        "PyTorch\n",
        "* `torch.Size([N, C, H, W])`\n",
        "\n",
        "[source](https://towardsdatascience.com/convert-images-to-tensors-in-pytorch-and-tensorflow-f0ab01383a03)"
      ],
      "metadata": {
        "id": "ehLsDo3onxB4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read TF Records"
      ],
      "metadata": {
        "id": "-1e-5dUQnz_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "ignore_order = tf.data.Options()\n",
        "ignore_order.experimental_deterministic = False\n",
        "batch_size = 128\n",
        "test_batch_size = 64"
      ],
      "metadata": {
        "id": "BSamGwJen2Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ImageNet"
      ],
      "metadata": {
        "id": "nXrC0wiIn4f8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_tfrecord(self, data_):\n",
        "\n",
        "  features = {\n",
        "      'image/class/label': tf.io.FixedLenFeature([], tf.int64),\n",
        "      'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
        "  }\n",
        "    # decode the TFRecord\n",
        "  tf_record = tf.io.parse_single_example(data_, features)\n",
        "    \n",
        "  # Typical code for decoding compressed images\n",
        "  image = tf.io.decode_jpeg(tf_record['image/encoded'], channels=3)\n",
        "  # image_ = tf.io.decode_jpeg(tf_record['image/encoded'], channels=3)\n",
        "\n",
        "  #  --> (128, 128, 3)resize tensor to 128 x 128 \n",
        "  image = tf.image.resize(image, [128, 128])\n",
        "  # image_1 = tf.image.resize(image, [128, 128])\n",
        "  \n",
        "  # --> # (1, 224, 224, 3)batch_size in front\n",
        "  image = tf.expand_dims(image, axis=0) \n",
        "  # image_2 = tf.expand_dims(image_1, axis=0)           \n",
        "  \n",
        "  # convert tensor to torch format: \n",
        "  # [N, H, W, C] --> [N, C, H, W]\n",
        "  image = tf.transpose(image, perm=[0, 3, 1, 2])\n",
        "  # print(f'image_3 TF tensor: {tf.shape(image_3)}')\n",
        "\n",
        "  label = tf_record['image/class/label']\n",
        "\n",
        "  return image, label #, pid"
      ],
      "metadata": {
        "id": "sG671bdun5U4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = [\n",
        "             'gs://imagenet-jt/train/train-00000-of-01024',\n",
        "]\n",
        "\n",
        "dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
        "dataset = dataset.with_options(ignore_order)\n",
        "\n",
        "# decoding a tf.data.TFRecordDataset\n",
        "dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "for image, label in dataset.take(1):\n",
        "  # image_torch = torch.from_numpy(image.numpy())\n",
        "  # print(image_torch)\n",
        "  print(\"Image shape {}, label={}\".format(image.numpy().shape, label))"
      ],
      "metadata": {
        "id": "GF7Ccezln9I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Torch Iterable Dataset\n",
        "\n",
        "Create a custom iterable dataset for PyTorch `DataLoader`"
      ],
      "metadata": {
        "id": "HF3yTU59oOo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class My_TF_Torch_Dataset(IterableDataset):\n",
        "    \n",
        "    def __init__(self, data_file_list, batch_size, length): # batch_size\n",
        "        self.data_file_list = data_file_list # list of filenames\n",
        "        self.batch_size = batch_size\n",
        "        self.length = length\n",
        "        \n",
        "    def __len__(self, length):\n",
        "      return self.length\n",
        "        \n",
        "    def read_tfrecord(self, data_):\n",
        "\n",
        "      features = {\n",
        "          'image/class/label': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
        "      }\n",
        "        # decode the TFRecord\n",
        "      tf_record = tf.io.parse_single_example(data_, features)\n",
        "        \n",
        "      # Typical code for decoding compressed images\n",
        "      image = tf.io.decode_jpeg(tf_record['image/encoded'], channels=3)\n",
        "      # image_ = tf.io.decode_jpeg(tf_record['image/encoded'], channels=3)\n",
        "\n",
        "      #  --> (128, 128, 3)resize tensor to 128 x 128 \n",
        "      image = tf.image.resize(image, [128, 128])\n",
        "      # image_1 = tf.image.resize(image, [128, 128])\n",
        "      \n",
        "      # --> # (1, 224, 224, 3)batch_size in front\n",
        "      image = tf.expand_dims(image, axis=0) \n",
        "      # image_2 = tf.expand_dims(image_1, axis=0)           \n",
        "      \n",
        "      # convert tensor to torch format: \n",
        "      # [N, H, W, C] --> [N, C, H, W]\n",
        "      image = tf.transpose(image, perm=[0, 3, 1, 2])\n",
        "      # print(f'image_3 TF tensor: {tf.shape(image_3)}')\n",
        "\n",
        "      label = tf_record['image/class/label']\n",
        "\n",
        "      return image, label #, pid\n",
        "\n",
        "        \n",
        "    def create_dataset(self, data_file_list):\n",
        "      \n",
        "      # set configs\n",
        "      AUTOTUNE = tf.data.AUTOTUNE\n",
        "      ignore_order = tf.data.Options()\n",
        "      ignore_order.experimental_deterministic = False\n",
        "\n",
        "      dataset = tf.data.Dataset.list_files(\n",
        "          data_file_list,\n",
        "          shuffle=False,\n",
        "      )\n",
        "      dataset = tf.data.TFRecordDataset(\n",
        "          dataset, \n",
        "          num_parallel_reads=AUTOTUNE,\n",
        "      )\n",
        "      dataset = dataset.with_options(\n",
        "          ignore_order\n",
        "      )\n",
        "      # dataset = dataset.batch(\n",
        "      #     batch_size=self.batch_size,\n",
        "      #     drop_remainder=True,\n",
        "      #     num_parallel_calls=AUTOTUNE,\n",
        "      #     deterministic=False,\n",
        "      #     name=\"batch_for_vector_mapping\",\n",
        "      # )\n",
        "      dataset = dataset.map(\n",
        "          self.read_tfrecord,\n",
        "          num_parallel_calls=AUTOTUNE,\n",
        "      )\n",
        "      # dataset = dataset.prefetch(\n",
        "      #     buffer_size=AUTOTUNE,\n",
        "      #     name=\"prefetch_data_b4_unbatch\",\n",
        "      # )\n",
        "      # dataset = dataset.unbatch()\n",
        "\n",
        "      return dataset\n",
        "\n",
        "\n",
        "    def get_torch_tensors(self, train_files):\n",
        "\n",
        "      tf_ds = self.create_dataset(train_files) \n",
        "      \n",
        "      for image, label in tf_ds:\n",
        "        # print(\"Image shape {}, label={}\".format(image.numpy().shape, label))   \n",
        "\n",
        "        image_torch = torch.from_numpy(image.numpy())\n",
        "        label_torch = int(label.numpy())\n",
        "        # print(\"image_torch shape {}, label={}\".format(image_torch.size(), label_torch))\n",
        "\n",
        "        yield image_torch, label_torch\n",
        "\n",
        "    # def get_stream(self, data_list):\n",
        "    #     return chain.from_iterable(map(self.process_data, cycle(data_list)))\n",
        "    #     # return chain.from_iterable(map(self.process_data, cycle( ? )))\n",
        "    \n",
        "    # def get_streams(self, train_files_this):\n",
        "      # return zip(*[self.get_torch_tensors(self.train_files_this) for _ in range(self.batch_size)]) # split_size\n",
        "\n",
        "    def __iter__(self):\n",
        "      \n",
        "      train_files_this = self.data_file_list\n",
        "      worker_info = torch.utils.data.get_worker_info()\n",
        "\n",
        "      if worker_info is not None:\n",
        "        wid = worker_info.id\n",
        "        num_workers = worker_info.num_workers\n",
        "        worker_train_files = train_files_this[wid::num_workers] \n",
        "      else:\n",
        "        worker_train_files = train_files_this\n",
        "\n",
        "      print(f\"In __iter__ : Worker_id: {wid} of {num_workers}; files: {worker_train_files}\")\n",
        "\n",
        "      return self.get_torch_tensors(worker_train_files)"
      ],
      "metadata": {
        "id": "yxsy6tTIoZSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = [\n",
        "             'gs://imagenet-jt/train/train-00000-of-01024',\n",
        "]\n",
        "epoch_length = len(filenames) * 1252\n",
        "\n",
        "dataset = My_TF_Torch_Dataset(filenames, batch_size=2, length=epoch_length)\n",
        "\n",
        "loader = DataLoader(dataset, batch_size=None, num_workers=2)"
      ],
      "metadata": {
        "id": "CCfLUZtgoiIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, train_labels = next(iter(loader))\n",
        "\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "# print(f\"Labels batch shape: {len(train_labels)}\")\n",
        "\n",
        "print(f\"Label: {train_labels}\")\n",
        "print(f\"Image: {train_features}\")"
      ],
      "metadata": {
        "id": "2CkCqWY1BiIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data in loader:\n",
        "  print(f\"Batch size: {len(data)}\")\n",
        "  print(data)\n",
        "  break"
      ],
      "metadata": {
        "id": "hWfz01scojY5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}