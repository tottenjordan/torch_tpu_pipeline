{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "creating-custom-torch-datasets.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Dataset Class and Custom Dataset objects"
      ],
      "metadata": {
        "id": "UfCwBYiD-Eoa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "le75DdXg98J2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, IterableDataset, DataLoader\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Letâ€™s first mock a simple dataset by creating a `Dataset` of all numbers from 1 to 1000. We'll aptly name this the `NumbersDataset`."
      ],
      "metadata": {
        "id": "crLQa3zD-NUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NumbersDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.samples = list(range(1, 1001))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    dataset = NumbersDataset()\n",
        "    print(len(dataset))\n",
        "    print(dataset[100])\n",
        "    print(dataset[122:361])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZCmkdr6-L7p",
        "outputId": "a7177355-7f12-4b7d-e1ce-08782a2dd3d4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "101\n",
            "[123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extend dataset so it can store all whole numbers between an interval low and high"
      ],
      "metadata": {
        "id": "dER_sWhY-T-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NumbersDataset(Dataset):\n",
        "    def __init__(self, low, high):\n",
        "        self.samples = list(range(low, high))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    dataset = NumbersDataset(2821, 8295)\n",
        "    print(len(dataset))\n",
        "    print(dataset[100])\n",
        "    print(dataset[122:361])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FGWYIY4-Wl6",
        "outputId": "c48cb246-de35-4692-aefa-cf8cb34f2882"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5474\n",
            "2921\n",
            "[2943, 2944, 2945, 2946, 2947, 2948, 2949, 2950, 2951, 2952, 2953, 2954, 2955, 2956, 2957, 2958, 2959, 2960, 2961, 2962, 2963, 2964, 2965, 2966, 2967, 2968, 2969, 2970, 2971, 2972, 2973, 2974, 2975, 2976, 2977, 2978, 2979, 2980, 2981, 2982, 2983, 2984, 2985, 2986, 2987, 2988, 2989, 2990, 2991, 2992, 2993, 2994, 2995, 2996, 2997, 2998, 2999, 3000, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009, 3010, 3011, 3012, 3013, 3014, 3015, 3016, 3017, 3018, 3019, 3020, 3021, 3022, 3023, 3024, 3025, 3026, 3027, 3028, 3029, 3030, 3031, 3032, 3033, 3034, 3035, 3036, 3037, 3038, 3039, 3040, 3041, 3042, 3043, 3044, 3045, 3046, 3047, 3048, 3049, 3050, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3058, 3059, 3060, 3061, 3062, 3063, 3064, 3065, 3066, 3067, 3068, 3069, 3070, 3071, 3072, 3073, 3074, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3083, 3084, 3085, 3086, 3087, 3088, 3089, 3090, 3091, 3092, 3093, 3094, 3095, 3096, 3097, 3098, 3099, 3100, 3101, 3102, 3103, 3104, 3105, 3106, 3107, 3108, 3109, 3110, 3111, 3112, 3113, 3114, 3115, 3116, 3117, 3118, 3119, 3120, 3121, 3122, 3123, 3124, 3125, 3126, 3127, 3128, 3129, 3130, 3131, 3132, 3133, 3134, 3135, 3136, 3137, 3138, 3139, 3140, 3141, 3142, 3143, 3144, 3145, 3146, 3147, 3148, 3149, 3150, 3151, 3152, 3153, 3154, 3155, 3156, 3157, 3158, 3159, 3160, 3161, 3162, 3163, 3164, 3165, 3166, 3167, 3168, 3169, 3170, 3171, 3172, 3173, 3174, 3175, 3176, 3177, 3178, 3179, 3180, 3181]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test IterableDatasets"
      ],
      "metadata": {
        "id": "_BYjJ14j-mou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import cycle, islice, chain\n",
        "\n",
        "data = [0,1,2,3,4,5,6,7,8,9]"
      ],
      "metadata": {
        "id": "7DhNYwmz-uwB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic"
      ],
      "metadata": {
        "id": "ZKjuC75Q_Cc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyIterableDataset(IterableDataset):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        \n",
        "    def __iter__(self):\n",
        "        return iter(self.data)\n",
        "    \n",
        "iterable_dataset = MyIterableDataset(data)\n",
        "\n",
        "loader = DataLoader(iterable_dataset, batch_size=4)\n",
        "\n",
        "for batch in loader:\n",
        "    print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkeixAos_DvV",
        "outputId": "ac620751-4b5c-47aa-ae7c-b6efe4afcefd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3])\n",
            "tensor([4, 5, 6, 7])\n",
            "tensor([8, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iterate through stream of data\n",
        "\n"
      ],
      "metadata": {
        "id": "ho1uYaq1_GZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyIterableDataset(IterableDataset):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        \n",
        "    def process_data(self, data):\n",
        "        for x in data:\n",
        "            yield x\n",
        "    \n",
        "    def get_stream(self, data):\n",
        "        return cycle(self.process_data(data))\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self.get_stream(self.data)\n",
        "    \n",
        "iterable_dataset = MyIterableDataset(data)\n",
        "\n",
        "loader = DataLoader(iterable_dataset, batch_size=4)\n",
        "\n",
        "for batch in islice(loader, 8):\n",
        "    print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGPHOD3k_Gvy",
        "outputId": "3c2c0061-07d8-418f-c516-16e437a3580a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3])\n",
            "tensor([4, 5, 6, 7])\n",
            "tensor([8, 9, 0, 1])\n",
            "tensor([2, 3, 4, 5])\n",
            "tensor([6, 7, 8, 9])\n",
            "tensor([0, 1, 2, 3])\n",
            "tensor([4, 5, 6, 7])\n",
            "tensor([8, 9, 0, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stream data from multiple files"
      ],
      "metadata": {
        "id": "UQ9r7c6u_KYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyIterableDataset(IterableDataset):\n",
        "    \n",
        "    def __init__(self, data_list):\n",
        "        self.data_list = data_list\n",
        "        \n",
        "    def process_data(self, data):\n",
        "        for x in data:\n",
        "            yield x\n",
        "    \n",
        "    def get_stream(self, data_list):\n",
        "        return chain.from_iterable(map(self.process_data, cycle(data_list)))\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self.get_stream(self.data_list)\n",
        "    \n",
        "data_list = [\n",
        "    [12, 13, 14, 15, 16, 17],\n",
        "    [27, 28, 29],\n",
        "    [31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
        "    [40, 41, 42, 43],\n",
        "]\n",
        "\n",
        "iterable_dataset = MyIterableDataset(data_list)\n",
        "\n",
        "loader = DataLoader(iterable_dataset, batch_size=4)\n",
        "\n",
        "for batch in islice(loader, 8):\n",
        "    print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXt019rq_KtB",
        "outputId": "bab020ee-f61a-47ff-e1f8-9f8224d5bbda"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([12, 13, 14, 15])\n",
            "tensor([16, 17, 27, 28])\n",
            "tensor([29, 31, 32, 33])\n",
            "tensor([34, 35, 36, 37])\n",
            "tensor([38, 39, 40, 41])\n",
            "tensor([42, 43, 12, 13])\n",
            "tensor([14, 15, 16, 17])\n",
            "tensor([27, 28, 29, 31])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Return batches of sequences"
      ],
      "metadata": {
        "id": "DGcTCP-k_Nzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyIterableDataset(IterableDataset):\n",
        "    \n",
        "    def __init__(self, data_list, batch_size):\n",
        "        self.data_list = data_list\n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "    def process_data(self, data):\n",
        "        for x in data:\n",
        "            yield x\n",
        "    \n",
        "    def get_stream(self, data_list):\n",
        "        return chain.from_iterable(map(self.process_data, cycle(data_list)))\n",
        "    \n",
        "    def get_streams(self):\n",
        "        return zip(*[self.get_stream(self.data_list) for _ in range(self.batch_size)])\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self.get_streams()\n",
        "    \n",
        "iterable_dataset = MyIterableDataset(data_list, batch_size=4)\n",
        "\n",
        "loader = DataLoader(iterable_dataset, batch_size=None)\n",
        "\n",
        "for batch in islice(loader, 8):\n",
        "    print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DQqEh--_So2",
        "outputId": "5d9056b7-e6ef-4ce2-b845-7685c0fd59a5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12, 12, 12, 12]\n",
            "[13, 13, 13, 13]\n",
            "[14, 14, 14, 14]\n",
            "[15, 15, 15, 15]\n",
            "[16, 16, 16, 16]\n",
            "[17, 17, 17, 17]\n",
            "[27, 27, 27, 27]\n",
            "[28, 28, 28, 28]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Partition data into groups, feed each group into a single stream"
      ],
      "metadata": {
        "id": "6cCWG3yS_XUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class MyIterableDataset(IterableDataset):\n",
        "    \n",
        "    def __init__(self, data_list, batch_size):\n",
        "        self.data_list = data_list\n",
        "        self.batch_size = batch_size\n",
        "    \n",
        "    @property\n",
        "    def shuffled_data_list(self):\n",
        "        return random.sample(self.data_list, len(self.data_list))\n",
        "    \n",
        "    def process_data(self, data):\n",
        "        for x in data:\n",
        "            yield x\n",
        "    \n",
        "    def get_stream(self, data_list):\n",
        "        return chain.from_iterable(map(self.process_data, cycle(data_list)))\n",
        "    \n",
        "    def get_streams(self):\n",
        "        return zip(*[self.get_stream(self.shuffled_data_list) for _ in range(self.batch_size)])\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self.get_streams()\n",
        "    \n",
        "iterable_dataset = MyIterableDataset(data_list, batch_size=4)\n",
        "\n",
        "loader = DataLoader(iterable_dataset, batch_size=None)\n",
        "\n",
        "for batch in islice(loader, 12):\n",
        "    print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zObYtw0P_ZI1",
        "outputId": "4bea08a3-ad66-45b8-8ad3-bc3a3d43c01e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12, 27, 31, 12]\n",
            "[13, 28, 32, 13]\n",
            "[14, 29, 33, 14]\n",
            "[15, 40, 34, 15]\n",
            "[16, 41, 35, 16]\n",
            "[17, 42, 36, 17]\n",
            "[27, 43, 37, 40]\n",
            "[28, 12, 38, 41]\n",
            "[29, 13, 39, 42]\n",
            "[40, 14, 40, 43]\n",
            "[41, 15, 41, 27]\n",
            "[42, 16, 42, 28]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parallel distribution"
      ],
      "metadata": {
        "id": "llP9nCW9_ckp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def worker_init_fn(_):\n",
        "#     worker_info = torch.utils.data.get_Worker_info()\n",
        "    \n",
        "#     dataset = worker_info.dataset\n",
        "#     worker_id = worker_info.id\n",
        "#     split_size = len(dataset.data) // worker_info.num_workers\n",
        "    \n",
        "#     dataset.data = dataset.data[worker_id * split_size:(worker_id + 1) * split_size]\n",
        "\n",
        "import time\n",
        "\n",
        "class MyIterableDataset(IterableDataset):\n",
        "    \n",
        "    def __init__(self, data_list, batch_size):\n",
        "        self.data_list = data_list\n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "    @property\n",
        "    def shuffled_data_list(self):\n",
        "        return random.sample(self.data_list, len(self.data_list))\n",
        "    \n",
        "    def process_data(self, data):\n",
        "        for x in data:\n",
        "            worker = torch.utils.data.get_worker_info()\n",
        "            worker_id = id(self) if worker is not None else -1\n",
        "            \n",
        "            start = time.time()\n",
        "            time.sleep(0.1)\n",
        "            end = time.time()\n",
        "            \n",
        "            yield x, worker_id #, start, end\n",
        "            \n",
        "    def get_stream(self, data_list):\n",
        "        return chain.from_iterable(map(self.process_data, cycle(data_list)))\n",
        "    \n",
        "    def get_streams(self):\n",
        "        return zip(*[self.get_stream(self.shuffled_data_list) for _ in range(self.batch_size)])\n",
        "        \n",
        "    def __iter__(self):\n",
        "        return self.get_streams()\n",
        "    \n",
        "    @classmethod\n",
        "    def split_datasets(cls, data_list, batch_size, max_workers):\n",
        "        \n",
        "        for n in range(max_workers, 0, -1):\n",
        "            if batch_size % n == 0:\n",
        "                num_workers = n\n",
        "                break\n",
        "                \n",
        "        split_size = batch_size // num_workers\n",
        "        \n",
        "        return [cls(data_list, batch_size=split_size) for _ in range(num_workers)]\n",
        "    \n",
        "class MultiStreamDataLoader:\n",
        "    \n",
        "    def __init__(self, datasets):\n",
        "        self.datasets = datasets\n",
        "        \n",
        "    def get_stream_loaders(self):\n",
        "        return zip(*[DataLoader(dataset, num_workers=1, batch_size=None) for dataset in datasets])\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for batch_parts in self.get_stream_loaders():\n",
        "            yield list(chain(*batch_parts))\n",
        "                       "
      ],
      "metadata": {
        "id": "d21mroHM_dRS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = MyIterableDataset.split_datasets(data_list, batch_size=4, max_workers=1)\n",
        "\n",
        "loader = MultiStreamDataLoader(datasets) \n",
        "\n",
        "start = time.time()\n",
        "for batch in islice(loader, 12):\n",
        "    print(batch)\n",
        "end = time.time()\n",
        "print(\"time:\", end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfciIJhG_gl3",
        "outputId": "c68020d5-5097-4553-a51b-0444b448333e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12, 140394551490640], [31, 140394551490640], [27, 140394551490640], [40, 140394551490640]]\n",
            "[[13, 140394551490640], [32, 140394551490640], [28, 140394551490640], [41, 140394551490640]]\n",
            "[[14, 140394551490640], [33, 140394551490640], [29, 140394551490640], [42, 140394551490640]]\n",
            "[[15, 140394551490640], [34, 140394551490640], [12, 140394551490640], [43, 140394551490640]]\n",
            "[[16, 140394551490640], [35, 140394551490640], [13, 140394551490640], [12, 140394551490640]]\n",
            "[[17, 140394551490640], [36, 140394551490640], [14, 140394551490640], [13, 140394551490640]]\n",
            "[[27, 140394551490640], [37, 140394551490640], [15, 140394551490640], [14, 140394551490640]]\n",
            "[[28, 140394551490640], [38, 140394551490640], [16, 140394551490640], [15, 140394551490640]]\n",
            "[[29, 140394551490640], [39, 140394551490640], [17, 140394551490640], [16, 140394551490640]]\n",
            "[[31, 140394551490640], [12, 140394551490640], [40, 140394551490640], [17, 140394551490640]]\n",
            "[[32, 140394551490640], [13, 140394551490640], [41, 140394551490640], [27, 140394551490640]]\n",
            "[[33, 140394551490640], [14, 140394551490640], [42, 140394551490640], [28, 140394551490640]]\n",
            "time: 5.251341104507446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Increase workers"
      ],
      "metadata": {
        "id": "i4HPnsI7_naC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = MyIterableDataset.split_datasets(data_list, batch_size=4, max_workers=2)\n",
        "\n",
        "loader = MultiStreamDataLoader(datasets) \n",
        "\n",
        "start = time.time()\n",
        "for batch in islice(loader, 12):\n",
        "    print(batch)\n",
        "end = time.time()\n",
        "print(\"time:\", end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_Zf-Fqm_kRS",
        "outputId": "1ee1459d-a5ac-4be8-fe4e-8268f6c99430"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[27, 140394551489296], [31, 140394551489296], [12, 140394551488720], [12, 140394551488720]]\n",
            "[[28, 140394551489296], [32, 140394551489296], [13, 140394551488720], [13, 140394551488720]]\n",
            "[[29, 140394551489296], [33, 140394551489296], [14, 140394551488720], [14, 140394551488720]]\n",
            "[[12, 140394551489296], [34, 140394551489296], [15, 140394551488720], [15, 140394551488720]]\n",
            "[[13, 140394551489296], [35, 140394551489296], [16, 140394551488720], [16, 140394551488720]]\n",
            "[[14, 140394551489296], [36, 140394551489296], [17, 140394551488720], [17, 140394551488720]]\n",
            "[[15, 140394551489296], [37, 140394551489296], [40, 140394551488720], [27, 140394551488720]]\n",
            "[[16, 140394551489296], [38, 140394551489296], [41, 140394551488720], [28, 140394551488720]]\n",
            "[[17, 140394551489296], [39, 140394551489296], [42, 140394551488720], [29, 140394551488720]]\n",
            "[[31, 140394551489296], [12, 140394551489296], [43, 140394551488720], [31, 140394551488720]]\n",
            "[[32, 140394551489296], [13, 140394551489296], [27, 140394551488720], [32, 140394551488720]]\n",
            "[[33, 140394551489296], [14, 140394551489296], [28, 140394551488720], [33, 140394551488720]]\n",
            "time: 2.838979482650757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = MyIterableDataset.split_datasets(data_list, batch_size=128, max_workers=5)\n",
        "datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_cTxC5U_qrb",
        "outputId": "6164d512-652c-46ce-b202-104b50bb0148"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<__main__.MyIterableDataset at 0x7fb026f63e90>,\n",
              " <__main__.MyIterableDataset at 0x7fb026f63910>,\n",
              " <__main__.MyIterableDataset at 0x7fb026f63890>,\n",
              " <__main__.MyIterableDataset at 0x7fb026f63bd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Increase workers and batch size"
      ],
      "metadata": {
        "id": "kDsuYprU_tK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = MyIterableDataset.split_datasets(data_list, batch_size=4, max_workers=4)\n",
        "\n",
        "loader = MultiStreamDataLoader(datasets) \n",
        "\n",
        "start = time.time()\n",
        "for batch in islice(loader, 12):\n",
        "    print(batch)\n",
        "end = time.time()\n",
        "print(\"time:\", end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1hyZ11Z_sd1",
        "outputId": "2e89aff5-0a9b-4d7c-f901-6f4a7da537f8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[31, 140394544730384], [40, 140394544730448], [40, 140394544730512], [31, 140394544730576]]\n",
            "[[32, 140394544730384], [41, 140394544730448], [41, 140394544730512], [32, 140394544730576]]\n",
            "[[33, 140394544730384], [42, 140394544730448], [42, 140394544730512], [33, 140394544730576]]\n",
            "[[34, 140394544730384], [43, 140394544730448], [43, 140394544730512], [34, 140394544730576]]\n",
            "[[35, 140394544730384], [31, 140394544730448], [12, 140394544730512], [35, 140394544730576]]\n",
            "[[36, 140394544730384], [32, 140394544730448], [13, 140394544730512], [36, 140394544730576]]\n",
            "[[37, 140394544730384], [33, 140394544730448], [14, 140394544730512], [37, 140394544730576]]\n",
            "[[38, 140394544730384], [34, 140394544730448], [15, 140394544730512], [38, 140394544730576]]\n",
            "[[39, 140394544730384], [35, 140394544730448], [16, 140394544730512], [39, 140394544730576]]\n",
            "[[12, 140394544730384], [36, 140394544730448], [17, 140394544730512], [27, 140394544730576]]\n",
            "[[13, 140394544730384], [37, 140394544730448], [27, 140394544730512], [28, 140394544730576]]\n",
            "[[14, 140394544730384], [38, 140394544730448], [28, 140394544730512], [29, 140394544730576]]\n",
            "time: 1.4809131622314453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = MyIterableDataset.split_datasets(data_list, batch_size=4, max_workers=6)\n",
        "# worker_dataset = datasets[worker_count]\n",
        "loader = MultiStreamDataLoader(datasets) \n",
        "\n",
        "start = time.time()\n",
        "for batch in islice(loader, 12):\n",
        "    print(batch)\n",
        "end = time.time()\n",
        "print(\"time:\", end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBRUnc8q_sbJ",
        "outputId": "775cbd29-6805-42af-d86a-8e1de7762641"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[40, 140394544640656], [40, 140394544640336], [27, 140394544640592], [27, 140394544642640]]\n",
            "[[41, 140394544640656], [41, 140394544640336], [28, 140394544640592], [28, 140394544642640]]\n",
            "[[42, 140394544640656], [42, 140394544640336], [29, 140394544640592], [29, 140394544642640]]\n",
            "[[43, 140394544640656], [43, 140394544640336], [31, 140394544640592], [12, 140394544642640]]\n",
            "[[31, 140394544640656], [31, 140394544640336], [32, 140394544640592], [13, 140394544642640]]\n",
            "[[32, 140394544640656], [32, 140394544640336], [33, 140394544640592], [14, 140394544642640]]\n",
            "[[33, 140394544640656], [33, 140394544640336], [34, 140394544640592], [15, 140394544642640]]\n",
            "[[34, 140394544640656], [34, 140394544640336], [35, 140394544640592], [16, 140394544642640]]\n",
            "[[35, 140394544640656], [35, 140394544640336], [36, 140394544640592], [17, 140394544642640]]\n",
            "[[36, 140394544640656], [36, 140394544640336], [37, 140394544640592], [40, 140394544642640]]\n",
            "[[37, 140394544640656], [37, 140394544640336], [38, 140394544640592], [41, 140394544642640]]\n",
            "[[38, 140394544640656], [38, 140394544640336], [39, 140394544640592], [42, 140394544642640]]\n",
            "time: 1.4928984642028809\n"
          ]
        }
      ]
    }
  ]
}