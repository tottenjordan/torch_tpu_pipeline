{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch-tfrecords.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch TPU + TF Records"
      ],
      "metadata": {
        "id": "s3RG7UEInkSG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vrp4qpPznSy3"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
        "LOCATION = 'us-central1' \n",
        "!gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()"
      ],
      "metadata": {
        "id": "S2_NP5Psnf9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in sys.modules:\n",
        "  USER_FLAG = ''\n",
        "else:\n",
        "  USER_FLAG = '--user'"
      ],
      "metadata": {
        "id": "0iq_iXL3nhWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pip install"
      ],
      "metadata": {
        "id": "fmNvzxexnlaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cloud-tpu-client==0.10 torch==1.11.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl\n",
        "\n",
        "! pip install tensorflow\n",
        "\n",
        "! pip -q install google-cloud-storage==1.44.0\n",
        "\n",
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "DYkssegznmrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import packages"
      ],
      "metadata": {
        "id": "clTmTT5Mns30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds \n",
        "\n",
        "# import webdataset as wds\n",
        "\n",
        "import torchvision\n",
        "import torch\n",
        "from torch.utils.data import Dataset, IterableDataset, DataLoader\n",
        "import torch_xla\n",
        "import os\n",
        "\n",
        "import sys\n",
        "from itertools import cycle, islice, chain, count\n",
        "import random \n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) "
      ],
      "metadata": {
        "id": "fJ-LcQKHnrJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF vs Torch Tensors\n",
        "\n",
        "* N - batch size\n",
        "* H - height of image\n",
        "* W - width of image\n",
        "* C - numberof channels (usually 3 for RGB)\n",
        "\n",
        "Tensorflow \n",
        "* `shape=(N, H, W, C)`\n",
        "\n",
        "PyTorch\n",
        "* `torch.Size([N, C, H, W])`\n",
        "\n",
        "[source](https://towardsdatascience.com/convert-images-to-tensors-in-pytorch-and-tensorflow-f0ab01383a03)"
      ],
      "metadata": {
        "id": "ehLsDo3onxB4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read TF Records"
      ],
      "metadata": {
        "id": "-1e-5dUQnz_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "ignore_order = tf.data.Options()\n",
        "ignore_order.experimental_deterministic = False\n",
        "batch_size = 128\n",
        "test_batch_size = 64"
      ],
      "metadata": {
        "id": "BSamGwJen2Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ImageNet"
      ],
      "metadata": {
        "id": "nXrC0wiIn4f8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO:** convert `tf tensor` to `torch tensor`"
      ],
      "metadata": {
        "id": "9NGRh10voFI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_tfrecord(data):\n",
        "    features = {\n",
        "        # tf.string = byte string (not text string)\n",
        "        'image/class/label': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
        "    }\n",
        "    \n",
        "    # decode the TFRecord\n",
        "    tf_record = tf.io.parse_single_example(data, features)\n",
        "    \n",
        "    # Typical code for decoding compressed images\n",
        "    image = tf.io.decode_jpeg(tf_record['image/encoded'], channels=3)\n",
        "    # print(image)\n",
        "    image = tf.image.resize(image, [128, 128])\n",
        "    # image = tf.expand_dims(image, axis=0) # add another dimension at the front to get batch_size in front\n",
        "\n",
        "    # torch tensor\n",
        "    # image = image.numpy()\n",
        "    # image = torch.from_numpy(image)\n",
        "    \n",
        "    label = tf_record['image/class/label']\n",
        "    \n",
        "    # print(image)\n",
        "    \n",
        "    return image, label"
      ],
      "metadata": {
        "id": "sG671bdun5U4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = [\n",
        "             'gs://imagenet-jt/train/train-00000-of-01024',\n",
        "]\n",
        "\n",
        "dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
        "dataset = dataset.with_options(ignore_order)\n",
        "\n",
        "# decoding a tf.data.TFRecordDataset\n",
        "dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "for image, label in dataset.take(1):\n",
        "  # image_torch = torch.from_numpy(image.numpy())\n",
        "  # print(image_torch)\n",
        "  print(\"Image shape {}, label={}\".format(image.numpy().shape, label))"
      ],
      "metadata": {
        "id": "GF7Ccezln9I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Torch Iterable Dataset\n",
        "\n",
        "Create a custom iterable dataset for PyTorch `DataLoader`"
      ],
      "metadata": {
        "id": "HF3yTU59oOo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyIterable_tf_Dataset(IterableDataset):\n",
        "    \n",
        "    def __init__(self, data_list, batch_size, length):\n",
        "        self.data_list = data_list\n",
        "        self.batch_size = batch_size\n",
        "        self.length = length\n",
        "        \n",
        "    def __len__(self, length):\n",
        "        return self.length\n",
        "        \n",
        "    def read_tfrecord(self, data):\n",
        "      features = {\n",
        "          'image/class/label': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
        "      }\n",
        "        # decode the TFRecord\n",
        "      tf_record = tf.io.parse_single_example(data, features)\n",
        "        \n",
        "      # Typical code for decoding compressed images\n",
        "      image = tf.io.decode_jpeg(tf_record['image/encoded'], channels=3)\n",
        "\n",
        "      image = tf.image.resize(image, [128, 128])\n",
        "      # image = tf.expand_dims(image, axis=0) # add another dimension at the front to get batch_size in front\n",
        "\n",
        "      label = tf_record['image/class/label']\n",
        "  \n",
        "    \n",
        "      return image, label\n",
        "        \n",
        "    def create_dataset(self, data_list):\n",
        "        dataset = tf.data.Dataset.list_files(data_list)\n",
        "        dataset = tf.data.TFRecordDataset(dataset)\n",
        "        dataset = dataset.with_options(ignore_order)\n",
        "        dataset = dataset.map(self.read_tfrecord)\n",
        "        dataset = dataset.batch(self.batch_size, drop_remainder=True)\n",
        "        return dataset\n",
        "    \n",
        "#     property\n",
        "#     def shuffled_data_list(self):\n",
        "#         return random.sample(list(self.create_dataset(self.data_list)), self.length)\n",
        "\n",
        "    def process_data(self, data):\n",
        "        for x in data:\n",
        "            yield x\n",
        "\n",
        "    # def process_data(self, data):\n",
        "    #     for image, label in data:\n",
        "    #       image_torch = torch.from_numpy(image.numpy())\n",
        "    #       yield image_torch, label\n",
        "    \n",
        "    def get_stream(self, data_list):\n",
        "        return chain.from_iterable(map(self.process_data, cycle(data_list)))\n",
        "    \n",
        "    def get_streams(self):\n",
        "        return zip(*[self.get_stream(self.create_dataset(self.data_list)) for _ in range(self.batch_size)])\n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self.get_streams()"
      ],
      "metadata": {
        "id": "yxsy6tTIoZSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = [\n",
        "             'gs://imagenet-jt/train/train-00000-of-01024',\n",
        "]\n",
        "\n",
        "dataset = MyIterable_tf_Dataset(filenames, batch_size=2, length=4)\n",
        "\n",
        "loader = DataLoader(dataset, batch_size=None, num_workers=1)"
      ],
      "metadata": {
        "id": "CCfLUZtgoiIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data in loader:\n",
        "  print(data)"
      ],
      "metadata": {
        "id": "hWfz01scojY5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}